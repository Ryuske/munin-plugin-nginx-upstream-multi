#!/usr/bin/env python
#
# log_format "ua=[$upstream_addr] ut=[$upstream_response_time] us=[$upstream_status] cs=[$upstream_cache_status]"
#

import os, sys, re

# How we've been called
progName = sys.argv[0]
progName = progName[progName.rfind("/")+1:]

# Where to store plugin state
if "MUNIN_PLUGSTATE" in os.environ:
    stateDir = os.environ["MUNIN_PLUGSTATE"]
else:
    stateDir = None

# Which site configuration we should use
siteName = progName[len("nginx_upstream_multi_"):]

# Log path
if "log" in os.environ:
    logPath = os.environ["log"]
else:
    logPath = "/var/log/nginx/access.log"

# Http statuses list
httpStatusString = ("100:Continue;101:Switching protocols;102:Processing;200:OK;201:Created;202:Accepted;"
"203:Non-Authoritative Information;204:No content;205:Reset content;206:Partial content;207:Multi-status;"
"226:IM used;300:Multiple choices;301:Moved permanently;302:Moved temporarily;303:See other;304:Not modified;"
"305:Use proxy;307:Temporary redirect;400:Bad request;401:Unauthorized;402:Payment required;403:Forbidden;"
"404:Not found;405:Method not allowed;406:Not acceptable;407:Proxy Authentication Required;408:Request timeout;"
"409:Conflict;410:Gone;411:Length required;412:Precondition failed;413:Request entity too large;"
"414:Request URI too large;415:Usupported media type;416:Request range not satisfiable;417:Expectation failed;"
"422:Unprocessable entity;423:Locked;424:Failed dependency;425:Unordered collection;426:Upgrade required;"
"449:Retry with;456:Unrecoverable error;500:Internal server error;501:Not implemented;502:Bad gateway;"
"503:Service unavailable;504:Gateway timeout;505:HTTP version not supported;506:Variant also negotiates;"
"507:Insufficient storage;508:Loop detected;509:Bandwidth limit exceeded;510:Not extended")

httpStatusList = {}
for statusString in httpStatusString.split(";"):
    [code, title] = statusString.split(":")
    httpStatusList[code] = {
        "title" : title,
        "requests" : 0
    }

cacheStatusList = { "MISS" : 0, "EXPIRED" : 0, "UPDATING" : 0, "STALE" : 0, "HIT" : 0 }

# Parse upstreams
upstreams = {}
if "upstream" in os.environ:
    upstreamString = os.environ["upstream"]
    upstreamList = upstreamString.split()
    for upstream in upstreamList:
        upstreams[upstream] = {
            "requests" : 0,
            "time"     : 0,
            "cache"    : cacheStatusList,
            "http"     : httpStatusList
        }
else:
    raise Exception("No upstreams specified")

if len(sys.argv) == 2 and sys.argv[1] == "autoconf":
    print "yes"
elif len(sys.argv) == 2 and sys.argv[1] == "config":
    # Parent graph declaration
    print "multigraph nginx_upstream_multi_%s" % siteName.replace(".", "_")
    print "graph_title Nginx upstream stats"
    print "graph_vlabel Requests"
    print "graph_category nginx"
    for upstream in upstreams.keys():
        print "%s_requests.label %s" % (upstream.replace(".", "_").replace(":", "_"), upstream)

    # Requests graph declaration
    for upstream in upstreams.keys():
        print ""
        print "multigraph nginx_upstream_multi_%s.%s_requests" % (siteName.replace(".", "_"), upstream.replace(".", "_").replace(":", "_"))
        print "graph_title Requests number - %s" % upstream
        print "graph_vlabel Requests"
        print "graph_category nginx"
        print "%s_requests.label %s" % (upstream.replace(".", "_").replace(":", "_"), upstream)
        print ""

    # Times graph declaration
    for upstream in upstreams.keys():
        print ""
        print "multigraph nginx_upstream_multi_%s.%s_times" % (siteName.replace(".", "_"), upstream.replace(".", "_").replace(":", "_"))
        print "graph_title Request time - %s" % upstream
        print "graph_vlabel msec."
        print "graph_category nginx"
        print "%s_times.label %s" % (upstream.replace(".", "_").replace(":", "_"), upstream)
        print ""

    # HTTP Status codes graph declaration
    for upstream in upstreams.keys():
        print ""
        print "multigraph nginx_upstream_multi_%s.%s_statuses" % (siteName.replace(".", "_"), upstream.replace(".", "_").replace(":", "_"))
        print "graph_title HTTP - %s" % upstream
        print "graph_vlabel Requests"
        print "graph_category nginx"
        keylist = httpStatusList.keys()
        keylist.sort()
        for status in keylist:
            print "http%s_status.label %s - %s" % (status, status, httpStatusList[status]["title"])
        print ""

    # Cache status graph declaration
    for upstream in upstreams.keys():
        print ""
        print "multigraph nginx_upstream_multi_%s.%s_cache" % (siteName.replace(".", "_"), upstream.replace(".", "_").replace(":", "_"))
        print "graph_title Cache - %s" % upstream
        print "graph_vlabel Requests"
        print "graph_category nginx"
        for status in cacheStatusList:
            print "%s_cache.label %s" % (status.replace(".", "_"), status)
        print ""
else:
    lastBytePath = "%s/nginx_upstream_multi_%s_lastByte.txt" % (stateDir, siteName)

    lastByteHandle = None

    try:
        lastByteHandle = open(lastBytePath, "r")
        lastByte = int(lastByteHandle.read())
    except Exception:
        lastByte = 0

    if lastByteHandle != None:
        lastByteHandle.close()

    try:
        logHandle = open(logPath, "r")
    except Exception:
        print "Log file %s not readable" % logPath
        sys.exit(1)

    try:
        logSize = int(os.path.getsize(logPath))
    except ValueError:
        logSize = 0

    if logSize < lastByte:
        lastByte = 0

    regExp = re.compile(r"ua=\[(.*?)\]\s+ut=\[(.*?)\]\s+us=\[(.*?)\]\s+cs=\[(.*?)\]")

    logHandle.seek(lastByte)
    for line in logHandle:
        match = regExp.search(line)
        if (match):
            # Extract data
            address = match.group(1)
            time    = match.group(2)
            status  = match.group(3)
            cache   = match.group(4)

            # Replace separators by space
            address = address.replace(",", " ")
            address = address.replace(" : ", " ")
            address = re.sub("\s+", " ", address)

            time    = time.replace(",", " ")
            time    = time.replace(" : ", " ")
            time    = re.sub("\s+", " ", time)

            status  = status.replace(",", " ")
            status  = status.replace(" : ", " ")
            status  = re.sub("\s+", " ", status)

            cache   = cache.replace(",", " ")
            cache   = cache.replace(" : ", " ")
            cache   = re.sub("\s+", " ", cache)

            addresses = address.split()
            times     = time.split()
            statuses  = status.split()
            caches    = cache.split()

            index = 0
            for uAddress in addresses:
                if uAddress in upstreams.keys():
                    try:
                        uTime    = float(times[index])
                    except ValueError:
                        uTime    = 0
                    uStatus  = statuses[index]
                    uCache   = caches[index]
                    if uAddress != "-":
                        upstreams[uAddress]["requests"]                  += 1
                    if uTime != "-":
                        upstreams[uAddress]["time"]                      += uTime
                    if uStatus != "-":
                        upstreams[uAddress]["http"][uStatus]["requests"] += 1
                    if uCache != "-":
                        upstreams[uAddress]["cache"][uCache]             += 1
                index += 1

    try:
        lastByteHandle = open(lastBytePath, "w")
        lastByteHandle.write(str(logHandle.tell()))
        lastByteHandle.close()
    except Exception:
        sys.exit(1)

    logHandle.close()

    # Parent graph data
    for upstream in upstreams.keys():
        print "%s_requests.value %s" % (upstream.replace(".", "_").replace(":", "_"), upstreams[upstream]["requests"])

    # Requests graph data
    for upstream in upstreams.keys():
        print ""
        print "multigraph nginx_upstream_multi_%s.%s_requests" % (siteName.replace(".", "_"), upstream.replace(".", "_").replace(":", "_"))
        print "%s_requests.value %s" % (upstream.replace(".", "_").replace(":", "_"), upstreams[upstream]["requests"])
        print ""

    # Times graph data
    for upstream in upstreams.keys():
        uTime = 0
        if upstreams[upstream]["requests"] > 0:
            uTime = upstreams[upstream]["time"] / upstreams[upstream]["requests"]
        print ""
        print "multigraph nginx_upstream_multi_%s.%s_times" % (siteName.replace(".", "_"), upstream.replace(".", "_").replace(":", "_"))
        print "%s_times.value %s" % (upstream.replace(".", "_").replace(":", "_"), uTime)
        print ""

    # HTTP Status codes graph data
    for upstream in upstreams.keys():
        print ""
        print "multigraph nginx_upstream_multi_%s.%s_statuses" % (siteName.replace(".", "_"), upstream.replace(".", "_").replace(":", "_"))
        keylist = httpStatusList.keys()
        keylist.sort()
        for status in keylist:
            print "http%s_status.value %s" % (status, upstreams[upstream]["http"][status]["requests"])
        print ""

    # Cache status graph data
    for upstream in upstreams.keys():
        print ""
        print "multigraph nginx_upstream_multi_%s.%s_cache" % (siteName.replace(".", "_"), upstream.replace(".", "_").replace(":", "_"))
        for status in cacheStatusList:
            print "%s_cache.value %s" % (status.replace(".", "_"), upstreams[upstream]["cache"][status])
        print ""